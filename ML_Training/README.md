# Montreal Monument Detection - Core ML Training

This directory contains everything needed to train a custom Core ML model for detecting Montreal landmarks in your AR app.

## ğŸ¯ Overview

The training pipeline creates a Core ML model that can recognize these Montreal landmarks:

- **Notre-Dame Basilica** (`notre_dame_basilica`)
- **Olympic Stadium & Tower** (`olympic_stadium_tower`)
- **Mount Royal Cross** (`mount_royal_cross`)
- **Old Port Clock Tower** (`old_port_clock_tower`)
- **Saint Joseph's Oratory** (`saint_josephs_oratory`)

## ğŸš€ Quick Start

### 1. Run Setup

```bash
cd ML_Training
python setup.py
```

This will:

- âœ… Check system requirements
- âœ… Install Python dependencies
- âœ… Create directory structure
- âœ… Generate guides and documentation

### 2. Collect Training Data

Follow one of these approaches:

#### Option A: Manual Collection (Recommended)

```bash
# Read the detailed guide
open training_data/MANUAL_COLLECTION_GUIDE.md

# Collect images and organize them in:
# training_data/train/[landmark_name]/
# training_data/validation/[landmark_name]/
```

#### Option B: Automated Collection

```bash
# Configure Flickr API in collect_from_flickr.py
python collect_from_flickr.py
```

### 3. Train the Model

```bash
# Once you have sufficient training data:
python train_monument_model.py

# Output: models/MontrealMonuments.mlmodel
```

### 4. Integrate with iOS App

```bash
# Follow the integration guide:
open models/INTEGRATION_GUIDE.md

# Key steps:
# 1. Drag MontrealMonuments.mlmodel into Xcode
# 2. Add to app target
# 3. Your MonumentRecognitionService is already updated!
```

## ğŸ“ File Structure

```
ML_Training/
â”œâ”€â”€ README.md                    # This file
â”œâ”€â”€ setup.py                     # Environment setup script
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ train_monument_model.py      # Main training script
â”œâ”€â”€ collect_training_data.py     # Data collection utilities
â”œâ”€â”€ training_data/              # Training images directory
â”‚   â”œâ”€â”€ train/                  # Training set (80% of data)
â”‚   â”‚   â”œâ”€â”€ notre_dame_basilica/
â”‚   â”‚   â”œâ”€â”€ olympic_stadium_tower/
â”‚   â”‚   â”œâ”€â”€ mount_royal_cross/
â”‚   â”‚   â”œâ”€â”€ old_port_clock_tower/
â”‚   â”‚   â”œâ”€â”€ saint_josephs_oratory/
â”‚   â”‚   â””â”€â”€ background/          # Non-monument images
â”‚   â””â”€â”€ validation/             # Validation set (20% of data)
â”‚       â”œâ”€â”€ notre_dame_basilica/
â”‚       â”œâ”€â”€ olympic_stadium_tower/
â”‚       â”œâ”€â”€ mount_royal_cross/
â”‚       â”œâ”€â”€ old_port_clock_tower/
â”‚       â”œâ”€â”€ saint_josephs_oratory/
â”‚       â””â”€â”€ background/
â””â”€â”€ models/                     # Generated models
    â”œâ”€â”€ MontrealMonuments.mlmodel  # Final Core ML model
    â””â”€â”€ INTEGRATION_GUIDE.md       # iOS integration instructions
```

## ğŸ¯ Training Requirements

### Minimum Dataset Size

- **100+ images per landmark** for training (500+ total)
- **20+ images per landmark** for validation (100+ total)
- **200+ background images** for training
- **40+ background images** for validation

### Image Quality Guidelines

- **Resolution**: Minimum 224x224 pixels
- **Format**: JPG or PNG
- **Quality**: Clear, well-lit, sharp images
- **Variety**: Different angles, lighting, seasons, weather

### Diversity Requirements

- ğŸ“¸ Multiple viewing angles (close-up, wide, aerial)
- ğŸŒ… Various lighting conditions (day, night, golden hour)
- ğŸŒ¦ï¸ Different weather conditions (clear, cloudy, rainy)
- ğŸ‘¥ With and without people/crowds
- ğŸ“… Different seasons if possible

## ğŸ”§ Technical Details

### Model Architecture

- **Base Model**: ResNet50 (pre-trained on ImageNet)
- **Transfer Learning**: Fine-tuned on Montreal landmarks
- **Input Size**: 224x224x3 RGB images
- **Output**: 6 classes (5 landmarks + background)
- **Framework**: TensorFlow/Keras â†’ Core ML conversion

### Training Configuration

- **Optimizer**: Adam with learning rate scheduling
- **Augmentation**: Rotation, shifts, zoom, flip
- **Validation Split**: 20% of data
- **Early Stopping**: Prevents overfitting
- **Batch Size**: 32 (adjustable based on memory)

### Performance Optimization

- **Temporal Smoothing**: Reduces detection flickering
- **Confidence Thresholding**: Filters low-confidence predictions
- **Model Quantization**: Optimized for mobile deployment

## ğŸ“Š Monitoring Training

### Check Dataset Status

```bash
python collect_training_data.py
```

### Validate Training Progress

```bash
# Monitor training logs for:
# - Training/validation accuracy
# - Loss reduction over epochs
# - Early stopping triggers
```

### Test Model Performance

```bash
# After training, test in iOS simulator or device
# Monitor console logs for detection confidence scores
```

## ğŸš¨ Troubleshooting

### Common Issues

#### 1. Import Errors

```bash
# Solution: Install requirements
pip install -r requirements.txt
```

#### 2. Insufficient Training Data

```bash
# Solution: Collect more images
python collect_training_data.py  # Check current status
# Follow MANUAL_COLLECTION_GUIDE.md
```

#### 3. Model Not Loading in iOS

```bash
# Solutions:
# 1. Check Xcode project target membership
# 2. Verify model file is in app bundle
# 3. Check iOS version compatibility
```

#### 4. Low Detection Accuracy

```bash
# Solutions:
# 1. Collect more diverse training data
# 2. Increase training epochs
# 3. Adjust confidence threshold in iOS app
# 4. Add more data augmentation
```

#### 5. Memory Issues During Training

```bash
# Solutions:
# 1. Reduce batch size in train_monument_model.py
# 2. Resize images to smaller dimensions
# 3. Use gradient checkpointing
```

## ğŸ“ Advanced Usage

### Custom Model Architecture

Edit `train_monument_model.py` to:

- Change base model (ResNet50 â†’ MobileNet, EfficientNet)
- Adjust layer sizes and dropout rates
- Modify data augmentation parameters

### Additional Landmarks

To add new landmarks:

1. Update `landmarks` list in training scripts
2. Add corresponding directories
3. Update iOS `MontrealLandmark.swift` model
4. Collect training data for new landmarks

### Model Optimization

- **Quantization**: Reduce model size for faster inference
- **Pruning**: Remove unnecessary model weights
- **Knowledge Distillation**: Create smaller student models

## ğŸ“š Resources

### Documentation

- [Core ML Documentation](https://developer.apple.com/documentation/coreml)
- [Vision Framework Guide](https://developer.apple.com/documentation/vision)
- [TensorFlow Core ML Tools](https://github.com/apple/coremltools)

### Datasets

- [Flickr API](https://www.flickr.com/services/api/) - Creative Commons images
- [Wikimedia Commons](https://commons.wikimedia.org/) - Free-use images
- [Montreal Tourism](https://www.mtl.org/) - Official tourism photos

### Training Resources

- [Transfer Learning Guide](https://www.tensorflow.org/tutorials/images/transfer_learning)
- [Data Augmentation Best Practices](https://www.tensorflow.org/tutorials/images/data_augmentation)
- [Core ML Model Optimization](https://developer.apple.com/videos/play/wwdc2019/704/)

## ğŸ¤ Contributing

To improve the model:

1. Collect higher quality training data
2. Experiment with different architectures
3. Add data augmentation techniques
4. Optimize for mobile performance
5. Test on various iOS devices

## ğŸ“„ License

This training code is provided under the same license as the main MonuMentAR project.

---

**Happy Training!** ğŸ›ï¸âœ¨

For questions or issues, check the troubleshooting section above or review the detailed guides in each directory.

